{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload kaggle.json API key\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Install packages\n",
        "!pip install -q kaggle \"tensorflow>=2.17.0\" gradio matplotlib\n",
        "\n",
        "# Python imports\n",
        "import os, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup Kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset (skip if already present)\n",
        "if not os.path.exists(\"/content/new-plant-diseases-dataset\"):\n",
        "    !kaggle datasets download -d vipoooool/new-plant-diseases-dataset -p /content\n",
        "    !unzip -q /content/new-plant-diseases-dataset.zip -d /content/new-plant-diseases-dataset\n",
        "\n",
        "!ls -lah /content/new-plant-diseases-dataset | sed -n '1,20p'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "N_LAST_LAYERS = 10   # Unfreeze last 10 layers for fine-tuning\n",
        "SEED = 1337\n",
        "NUM_CLASSES = 38\n",
        "\n",
        "# Dataset paths\n",
        "train_dir = \"/content/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
        "valid_dir = \"/content/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
        "\n",
        "# Verify paths\n",
        "for p in [train_dir, valid_dir]:\n",
        "    if not os.path.exists(p):\n",
        "        print(f\"ERROR: path not found: {p}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "print(\"train_dir:\", train_dir)\n",
        "print(\"valid_dir:\", valid_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images(directory):\n",
        "    total_images = 0\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            num_images = len(os.listdir(class_path))\n",
        "            class_counts[class_name] = num_images\n",
        "            total_images += num_images\n",
        "    return total_images, class_counts\n",
        "\n",
        "train_total, train_counts = count_images(train_dir)\n",
        "valid_total, valid_counts = count_images(valid_dir)\n",
        "\n",
        "print(f\"Training images: {train_total}\")\n",
        "print(f\"Validation images: {valid_total}\")\n",
        "print(f\"Number of classes: {len(train_counts)}\")\n",
        "print(f\"\\nClass distribution (first 10):\")\n",
        "for i, (class_name, count) in enumerate(list(train_counts.items())[:10]):\n",
        "    print(f\"  {class_name}: {count} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def show_sample_images(base_path, num_classes=5, images_per_class=3):\n",
        "    class_names = os.listdir(base_path)\n",
        "    random_classes = random.sample(class_names, min(num_classes, len(class_names)))\n",
        "    fig, axes = plt.subplots(num_classes, images_per_class, figsize=(12, 3*num_classes))\n",
        "    fig.suptitle('Sample Images from Dataset', fontsize=16)\n",
        "    for i, class_name in enumerate(random_classes):\n",
        "        class_path = os.path.join(base_path, class_name)\n",
        "        images = os.listdir(class_path)\n",
        "        random_images = random.sample(images, min(images_per_class, len(images)))\n",
        "        for j, img_name in enumerate(random_images):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = plt.imread(img_path)\n",
        "            axes[i, j].imshow(img)\n",
        "            axes[i, j].axis('off')\n",
        "            if j == 0:\n",
        "                axes[i, j].set_title(class_name.replace('___', '\\n'), fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_sample_images(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "# Training generator with light augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode='reflect'\n",
        ")\n",
        "\n",
        "# Validation generator \u2014 no augmentation\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Create generators\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "valid_gen = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Save class indices mapping\n",
        "class_indices = train_gen.class_indices\n",
        "class_names = {v: k for k, v in class_indices.items()}\n",
        "print(f\"Found {len(class_indices)} classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Load MobileNetV2 backbone (exclude top classification layer)\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "print(\"MobileNetV2 loaded successfully!\")\n",
        "print(f\"Total layers in base model: {len(base_model.layers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Freeze all layers initially\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Unfreeze last N layers for fine-tuning\n",
        "if N_LAST_LAYERS > 0:\n",
        "    for layer in base_model.layers[-N_LAST_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "# Count parameters\n",
        "trainable_count = sum([tf.size(w).numpy() for w in base_model.trainable_weights])\n",
        "non_trainable_count = sum([tf.size(w).numpy() for w in base_model.non_trainable_weights])\n",
        "print(f\"Trainable parameters: {trainable_count:,}\")\n",
        "print(f\"Non-trainable parameters: {non_trainable_count:,}\")\n",
        "print(f\"Unfrozen last {N_LAST_LAYERS} layers for fine-tuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Build model\n",
        "inputs = keras.Input(shape=IMG_SIZE + (3,))\n",
        "x = base_model(inputs, training=False)    # Frozen BatchNorm layers\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.35)(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs, name=\"mobilenetv2_plant_disease_classifier\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),   # Low LR for fine-tuning\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(\"Model compiled successfully!\")\n",
        "print(\"Optimizer: Adam (lr=1e-4)\")\n",
        "print(\"Loss function: Categorical Crossentropy\")\n",
        "print(\"Metrics: Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    # Save best model by validation accuracy\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"/content/mobilenetv2_best.keras\",\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Reduce LR when val_loss plateaus\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        verbose=1\n",
        "    ),\n",
        "    # Stop if no improvement\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=6,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "print(\"Callbacks configured:\")\n",
        "print(\"  1. ModelCheckpoint \u2014 Saves best model\")\n",
        "print(\"  2. ReduceLROnPlateau \u2014 Adjusts learning rate\")\n",
        "print(\"  3. EarlyStopping \u2014 Prevents overfitting\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_gen,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history.get('accuracy', []), label='train_accuracy')\n",
        "plt.plot(history.history.get('val_accuracy', []), label='val_accuracy')\n",
        "plt.xlabel('epoch'); plt.ylabel('accuracy')\n",
        "plt.legend(); plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history.get('loss', []), label='train_loss')\n",
        "plt.plot(history.history.get('val_loss', []), label='val_loss')\n",
        "plt.xlabel('epoch'); plt.ylabel('loss')\n",
        "plt.legend(); plt.title('Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_loss, val_acc = model.evaluate(valid_gen)\n",
        "print(f\"Validation loss: {val_loss:.4f}, accuracy: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_path = \"/content/mobilenetv2_final.keras\"\n",
        "model.save(final_path)\n",
        "print(\"Saved final model to:\", final_path)\n",
        "\n",
        "# Also save class indices for use in Flask app\n",
        "import json\n",
        "with open(\"/content/class_indices.json\", \"w\") as f:\n",
        "    json.dump(class_indices, f)\n",
        "print(\"Saved class indices to: /content/class_indices.json\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}